{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3612a7eb",
      "metadata": {
        "papermill": {
          "duration": 0.002351,
          "end_time": "2025-11-26T12:39:56.782286",
          "exception": false,
          "start_time": "2025-11-26T12:39:56.779935",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## CSIRO Image2Biomass â€“ 5-Head Model Inference\n",
        "\n",
        "This notebook runs inference using the 5-Head DINOv2 model with:\n",
        "- FiLM cross-stream conditioning\n",
        "- Attention pooling over tiles  \n",
        "- 5 independent regression heads (Green, Dead, Clover, GDM, Total)\n",
        "- TTA (Test-Time Augmentation) with flips\n",
        "- K-fold ensemble\n",
        "- **Log target support** (expm1 inverse transform)\n",
        "- **Dead derivation fix** (Dead = Total - GDM)\n",
        "- **Species auxiliary head** (8 classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ee52cf8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-26T12:39:56.787569Z",
          "iopub.status.busy": "2025-11-26T12:39:56.787301Z",
          "iopub.status.idle": "2025-11-26T12:41:55.526213Z",
          "shell.execute_reply": "2025-11-26T12:41:55.525318Z"
        },
        "papermill": {
          "duration": 118.743613,
          "end_time": "2025-11-26T12:41:55.527607",
          "exception": false,
          "start_time": "2025-11-26T12:39:56.783994",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "Backbone A: vit_base_patch14_reg4_dinov2.lvd142m (weight=0.8)\n",
            "Backbone B: vit_small_patch14_dinov2.lvd142m (weight=0.2)\n",
            "\n",
            "================= Loading test data =================\n",
            "Found 357 unique test images.\n",
            "\n",
            "================= Backbone A inference =================\n",
            "\n",
            "================= Loading vit_base_patch14_reg4_dinov2.lvd142m (5 folds) =================\n",
            "Model dir: /root/workspace/outputs/stage1_base\n",
            "Found 5 checkpoints\n",
            "fold0 => variant=tiled_film, backbone=vit_base_patch14_reg4_dinov2.lvd142m, input_res=518\n",
            "tiled_film_best_model_fold1.pth => variant=tiled_film, backbone=vit_base_patch14_reg4_dinov2.lvd142m, input_res=518\n",
            "tiled_film_best_model_fold2.pth => variant=tiled_film, backbone=vit_base_patch14_reg4_dinov2.lvd142m, input_res=518\n",
            "tiled_film_best_model_fold3.pth => variant=tiled_film, backbone=vit_base_patch14_reg4_dinov2.lvd142m, input_res=518\n",
            "tiled_film_best_model_fold4.pth => variant=tiled_film, backbone=vit_base_patch14_reg4_dinov2.lvd142m, input_res=518\n",
            "\n",
            "--- TTA view 1/3 (resize=518) ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                    \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- TTA view 2/3 (resize=518) ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                    \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- TTA view 3/3 (resize=518) ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                    \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================= Backbone B inference =================\n",
            "\n",
            "================= Loading vit_small_patch14_dinov2.lvd142m (5 folds) =================\n",
            "Model dir: /root/workspace/outputs/stage1_small\n",
            "Found 5 checkpoints\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Cannot find matching variant/backbone for tiled_film_best_model_fold0.pth. Detected tiled_film weights, please check training-inference consistency.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 578\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mðŸ“Š Visualization saved: ensemble_analysis.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 578\u001b[0m     final_5, df_long, df_unique, final_a, final_b \u001b[38;5;241m=\u001b[39m \u001b[43mrun_dual_backbone_ensemble\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m     sub, wide_df \u001b[38;5;241m=\u001b[39m create_submission(final_5, df_long, df_unique)\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m================= Generating Visualizations =================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn[3], line 437\u001b[0m, in \u001b[0;36mrun_dual_backbone_ensemble\u001b[0;34m()\u001b[0m\n\u001b[1;32m    434\u001b[0m final_a \u001b[38;5;241m=\u001b[39m run_inference_for_backbone(CFG\u001b[38;5;241m.\u001b[39mMODEL_DIR_A, CFG\u001b[38;5;241m.\u001b[39mBACKBONE_A, test_unique, CFG\u001b[38;5;241m.\u001b[39mTEST_IMAGE_DIR)\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m================= Backbone B inference =================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 437\u001b[0m final_b \u001b[38;5;241m=\u001b[39m \u001b[43mrun_inference_for_backbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL_DIR_B\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBACKBONE_B\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_unique\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTEST_IMAGE_DIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m final_a\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m final_b\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA/B results shape mismatch, cannot perform weighted fusion.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m================= Fusing predictions (A:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCFG\u001b[38;5;241m.\u001b[39mW_A\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, B:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCFG\u001b[38;5;241m.\u001b[39mW_B\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) =================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn[3], line 397\u001b[0m, in \u001b[0;36mrun_inference_for_backbone\u001b[0;34m(model_dir, backbone_name, test_unique, image_dir)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(ckpt_list)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m checkpoints\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    396\u001b[0m models \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 397\u001b[0m m1, v1, b1 \u001b[38;5;241m=\u001b[39m \u001b[43mload_fold_model_auto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGRID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackbone_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackbone_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m models\u001b[38;5;241m.\u001b[39mappend(m1)\n\u001b[1;32m    399\u001b[0m backbone_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(m1, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_res\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m518\u001b[39m))\n",
            "Cell \u001b[0;32mIn[3], line 355\u001b[0m, in \u001b[0;36mload_fold_model_auto\u001b[0;34m(path, grid, backbone_hint)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    353\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 355\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find matching variant/backbone for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Detected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtiled_film\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mis_film\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnon-film\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m weights, please check training-inference consistency.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    358\u001b[0m )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Cannot find matching variant/backbone for tiled_film_best_model_fold0.pth. Detected tiled_film weights, please check training-inference consistency."
          ]
        }
      ],
      "source": [
        "import os\n",
        "import gc\n",
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from typing import List, Tuple, Optional, Dict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import timm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.gridspec import GridSpec\n",
        "\n",
        "\n",
        "class CFG:\n",
        "    \"\"\"Configuration for 5-head model inference.\"\"\"\n",
        "    \n",
        "    # ==================== LOCAL TESTING MODE ====================\n",
        "    # Set LOCAL_TEST = True for local testing, False for Kaggle submission\n",
        "    LOCAL_TEST = True\n",
        "    \n",
        "    if LOCAL_TEST:\n",
        "        BASE_PATH = \"./data\"\n",
        "        TEST_CSV = os.path.join(BASE_PATH, \"train.csv\")  # Use train.csv for local OOF testing\n",
        "        TEST_IMAGE_DIR = os.path.join(BASE_PATH, \"train\")\n",
        "        MODEL_DIR = \"./outputs/5head_20251214_123456\"  # Update to your model directory\n",
        "    else:\n",
        "        BASE_PATH = \"/kaggle/input/csiro-biomass\"\n",
        "        TEST_CSV = os.path.join(BASE_PATH, \"test.csv\")\n",
        "        TEST_IMAGE_DIR = os.path.join(BASE_PATH, \"test\")\n",
        "        MODEL_DIR = \"/kaggle/input/your-model-dataset\"  # Update for Kaggle\n",
        "    \n",
        "    # Backbone config (must match training)\n",
        "    BACKBONE = \"vit_base_patch14_reg4_dinov2.lvd142m\"\n",
        "    \n",
        "    # ==================== INFERENCE SETTINGS ====================\n",
        "    SUBMISSION_FILE = \"submission.csv\"\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    BATCH_SIZE = 1\n",
        "    NUM_WORKERS = 0\n",
        "    \n",
        "    # Model architecture params (auto-loaded from results.json if available)\n",
        "    DROPOUT = 0.2\n",
        "    HIDDEN_RATIO = 0.5\n",
        "    GRID = (2, 2)\n",
        "    USE_FILM = True\n",
        "    USE_ATTENTION_POOL = True\n",
        "    USE_AUX_HEADS = True  # Set to True if model was trained with aux heads\n",
        "    \n",
        "    # ==================== NEW FEATURES ====================\n",
        "    # Log target: If model was trained with --use-log-target, apply expm1 to predictions\n",
        "    USE_LOG_TARGET = False  # Auto-detected from results.json\n",
        "    \n",
        "    # Dead derivation: Apply Dead = max(0, Total - GDM) post-processing\n",
        "    DERIVE_DEAD = True  # Recommended for better Dead predictions\n",
        "    \n",
        "    # TTA settings\n",
        "    USE_TTA = True  # Enable Test-Time Augmentation (3 views)\n",
        "    \n",
        "    ALL_TARGET_COLS = [\"Dry_Green_g\", \"Dry_Dead_g\", \"Dry_Clover_g\", \"GDM_g\", \"Dry_Total_g\"]\n",
        "    \n",
        "    # DINO backbone candidates for auto-detection (fallback)\n",
        "    DINO_CANDIDATES = [\n",
        "        \"vit_large_patch14_reg4_dinov2.lvd142m\",\n",
        "        \"vit_base_patch14_reg4_dinov2.lvd142m\",\n",
        "        \"vit_small_patch14_reg4_dinov2.lvd142m\",\n",
        "        \"vit_large_patch14_dinov2.lvd142m\",\n",
        "        \"vit_base_patch14_dinov2.lvd142m\",\n",
        "        \"vit_small_patch14_dinov2.lvd142m\",\n",
        "    ]\n",
        "\n",
        "\n",
        "def load_config_from_results(model_dir: str) -> Dict:\n",
        "    \"\"\"Load training config from results.json if available.\"\"\"\n",
        "    results_path = os.path.join(model_dir, \"results.json\")\n",
        "    if os.path.exists(results_path):\n",
        "        with open(results_path, \"r\") as f:\n",
        "            results = json.load(f)\n",
        "        config = results.get(\"config\", {})\n",
        "        print(f\"Loaded config from results.json:\")\n",
        "        for key in [\"backbone\", \"grid\", \"use_log_target\", \"stereo_correct_aug\"]:\n",
        "            if key in config:\n",
        "                print(f\"  {key}: {config[key]}\")\n",
        "        return config\n",
        "    return {}\n",
        "\n",
        "\n",
        "# Auto-load config\n",
        "if os.path.exists(CFG.MODEL_DIR):\n",
        "    _loaded_config = load_config_from_results(CFG.MODEL_DIR)\n",
        "    if _loaded_config:\n",
        "        CFG.BACKBONE = _loaded_config.get(\"backbone\", CFG.BACKBONE)\n",
        "        CFG.GRID = tuple(_loaded_config.get(\"grid\", CFG.GRID))\n",
        "        CFG.DROPOUT = _loaded_config.get(\"dropout\", CFG.DROPOUT)\n",
        "        CFG.HIDDEN_RATIO = _loaded_config.get(\"hidden_ratio\", CFG.HIDDEN_RATIO)\n",
        "        CFG.USE_LOG_TARGET = _loaded_config.get(\"use_log_target\", CFG.USE_LOG_TARGET)\n",
        "\n",
        "\n",
        "def get_device() -> torch.device:\n",
        "    \"\"\"Get best available device.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device(\"cuda\")\n",
        "    elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
        "        return torch.device(\"mps\")\n",
        "    return torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "# Update device\n",
        "CFG.DEVICE = get_device()\n",
        "\n",
        "\n",
        "def get_all_fold_checkpoints(model_dir: str, num_folds: int = 5) -> List[str]:\n",
        "    \"\"\"Get checkpoint paths for all folds of 5-head model.\"\"\"\n",
        "    paths = []\n",
        "    for fold in range(num_folds):\n",
        "        ckpt_path = os.path.join(model_dir, f\"5head_best_fold{fold}.pth\")\n",
        "        if os.path.exists(ckpt_path):\n",
        "            paths.append(ckpt_path)\n",
        "        else:\n",
        "            print(f\"  Warning: {ckpt_path} not found, skipping\")\n",
        "    return paths\n",
        "\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"5-Head DINOv2 Inference\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Device: {CFG.DEVICE}\")\n",
        "print(f\"Backbone: {CFG.BACKBONE}\")\n",
        "print(f\"Model dir: {CFG.MODEL_DIR}\")\n",
        "print(f\"Grid: {CFG.GRID}\")\n",
        "print(f\"Log target: {CFG.USE_LOG_TARGET}\")\n",
        "print(f\"Derive Dead: {CFG.DERIVE_DEAD}\")\n",
        "print(f\"TTA: {CFG.USE_TTA}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "class TestBiomassDataset(Dataset):\n",
        "    def __init__(self, df, transform, image_dir):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "        self.image_dir = image_dir\n",
        "        self.paths = self.df[\"image_path\"].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filename = os.path.basename(self.paths[idx])\n",
        "        full_path = os.path.join(self.image_dir, filename)\n",
        "        img = cv2.imread(full_path)\n",
        "        if img is None:\n",
        "            img = np.zeros((1000, 2000, 3), dtype=np.uint8)\n",
        "        else:\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        h, w, _ = img.shape\n",
        "        mid = w // 2\n",
        "        left = img[:, :mid]\n",
        "        right = img[:, mid:]\n",
        "\n",
        "        left_t = self.transform(image=left)[\"image\"]\n",
        "        right_t = self.transform(image=right)[\"image\"]\n",
        "        return left_t, right_t\n",
        "\n",
        "def _infer_input_res(m) -> int:\n",
        "    if hasattr(m, \"patch_embed\") and hasattr(m.patch_embed, \"img_size\"):\n",
        "        isz = m.patch_embed.img_size\n",
        "        return int(isz if isinstance(isz, (int, float)) else isz[0])\n",
        "    if hasattr(m, \"img_size\"):\n",
        "        isz = m.img_size\n",
        "        return int(isz if isinstance(isz, (int, float)) else isz[0])\n",
        "    dc = getattr(m, \"default_cfg\", {}) or {}\n",
        "    ins = dc.get(\"input_size\", None)\n",
        "    if ins:\n",
        "        if isinstance(ins, (tuple, list)) and len(ins) >= 2:\n",
        "            return int(ins[1])\n",
        "        return int(ins if isinstance(ins, (int, float)) else 224)\n",
        "    name = getattr(m, \"default_cfg\", {}).get(\"architecture\", \"\") or str(type(m))\n",
        "    if \"dinov2\" in name.lower():\n",
        "        return 518\n",
        "    return 224\n",
        "\n",
        "def _build_dino_by_name(name: str, pretrained: bool = False):\n",
        "    m = timm.create_model(name, pretrained=pretrained, num_classes=0)\n",
        "    feat = m.num_features\n",
        "    input_res = _infer_input_res(m)\n",
        "    return m, feat, input_res\n",
        "\n",
        "def _make_edges(L: int, parts: int) -> List[Tuple[int, int]]:\n",
        "    step = L // parts\n",
        "    edges = []\n",
        "    start = 0\n",
        "    for _ in range(parts - 1):\n",
        "        edges.append((start, start + step))\n",
        "        start += step\n",
        "    edges.append((start, L))\n",
        "    return edges\n",
        "\n",
        "\n",
        "class FiLM(nn.Module):\n",
        "    \"\"\"Feature-wise Linear Modulation layer.\"\"\"\n",
        "    \n",
        "    def __init__(self, in_dim: int) -> None:\n",
        "        super().__init__()\n",
        "        hidden = max(64, in_dim // 2)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden, in_dim * 2),\n",
        "        )\n",
        "    \n",
        "    def forward(self, context: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        gb = self.mlp(context)\n",
        "        gamma, beta = torch.chunk(gb, 2, dim=1)\n",
        "        return gamma, beta\n",
        "\n",
        "\n",
        "class AttentionPooling(nn.Module):\n",
        "    \"\"\"Learnable attention pooling over tiles.\"\"\"\n",
        "    \n",
        "    def __init__(self, dim: int) -> None:\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(dim, dim)\n",
        "        self.key = nn.Linear(dim, dim)\n",
        "        self.scale = dim ** -0.5\n",
        "    \n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        q = self.query(x.mean(dim=1, keepdim=True))  # (B, 1, D)\n",
        "        k = self.key(x)  # (B, T, D)\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale  # (B, 1, T)\n",
        "        attn = F.softmax(attn, dim=-1)\n",
        "        out = (attn @ x).squeeze(1)  # (B, D)\n",
        "        return out\n",
        "\n",
        "\n",
        "# Auxiliary head constants\n",
        "NUM_STATES = 4\n",
        "NUM_MONTHS = 10\n",
        "NUM_SPECIES = 8  # Added: Species classification head\n",
        "\n",
        "\n",
        "class FiveHeadDINO(nn.Module):\n",
        "    \"\"\"\n",
        "    5-Head DINOv2 model with FiLM conditioning and attention pooling.\n",
        "    All 5 biomass targets are predicted independently.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        backbone_name: str = \"vit_base_patch14_reg4_dinov2.lvd142m\",\n",
        "        grid: Tuple[int, int] = (2, 2),\n",
        "        pretrained: bool = False,\n",
        "        dropout: float = 0.2,\n",
        "        hidden_ratio: float = 0.5,\n",
        "        use_film: bool = True,\n",
        "        use_attention_pool: bool = True,\n",
        "        use_aux_heads: bool = False,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        \n",
        "        self.backbone, feat_dim, input_res = _build_dino_by_name(backbone_name, pretrained)\n",
        "        self.used_backbone_name = backbone_name\n",
        "        self.input_res = int(input_res)\n",
        "        self.feat_dim = feat_dim\n",
        "        self.grid = tuple(grid)\n",
        "        self.use_film = use_film\n",
        "        self.use_attention_pool = use_attention_pool\n",
        "        self.use_aux_heads = use_aux_heads\n",
        "        \n",
        "        # FiLM for left-right stream conditioning\n",
        "        if use_film:\n",
        "            self.film_left = FiLM(feat_dim)\n",
        "            self.film_right = FiLM(feat_dim)\n",
        "        \n",
        "        # Attention pooling for tiles\n",
        "        if use_attention_pool:\n",
        "            self.attn_pool_left = AttentionPooling(feat_dim)\n",
        "            self.attn_pool_right = AttentionPooling(feat_dim)\n",
        "        \n",
        "        # Combined features from left + right streams\n",
        "        self.combined_dim = feat_dim * 2\n",
        "        hidden_dim = max(64, int(self.combined_dim * hidden_ratio))\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        # Shared feature projection with LayerNorm\n",
        "        self.shared_proj = nn.Sequential(\n",
        "            nn.LayerNorm(self.combined_dim),\n",
        "            nn.Linear(self.combined_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "        \n",
        "        def _make_head(in_dim: int) -> nn.Sequential:\n",
        "            return nn.Sequential(\n",
        "                nn.Linear(in_dim, in_dim),\n",
        "                nn.GELU(),\n",
        "                nn.Dropout(dropout * 0.5),\n",
        "                nn.Linear(in_dim, 1),\n",
        "            )\n",
        "        \n",
        "        # 5 independent heads for biomass targets\n",
        "        self.head_green = _make_head(hidden_dim)\n",
        "        self.head_dead = _make_head(hidden_dim)\n",
        "        self.head_clover = _make_head(hidden_dim)\n",
        "        self.head_gdm = _make_head(hidden_dim)\n",
        "        self.head_total = _make_head(hidden_dim)\n",
        "        \n",
        "        # Auxiliary heads for State, Month, and Species classification\n",
        "        if use_aux_heads:\n",
        "            self.head_state = nn.Sequential(\n",
        "                nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "                nn.GELU(),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Linear(hidden_dim // 2, NUM_STATES),\n",
        "            )\n",
        "            self.head_month = nn.Sequential(\n",
        "                nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "                nn.GELU(),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Linear(hidden_dim // 2, NUM_MONTHS),\n",
        "            )\n",
        "            self.head_species = nn.Sequential(\n",
        "                nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "                nn.GELU(),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Linear(hidden_dim // 2, NUM_SPECIES),\n",
        "            )\n",
        "        \n",
        "        self.softplus = nn.Softplus(beta=1.0)\n",
        "    \n",
        "    def _collect_tiles(self, x: torch.Tensor) -> List[torch.Tensor]:\n",
        "        _, C, H, W = x.shape\n",
        "        r, c = self.grid\n",
        "        rows = _make_edges(H, r)\n",
        "        cols = _make_edges(W, c)\n",
        "        tiles = []\n",
        "        for rs, re in rows:\n",
        "            for cs, ce in cols:\n",
        "                xt = x[:, :, rs:re, cs:ce]\n",
        "                if xt.shape[-2:] != (self.input_res, self.input_res):\n",
        "                    xt = F.interpolate(xt, size=(self.input_res, self.input_res), \n",
        "                                       mode=\"bilinear\", align_corners=False)\n",
        "                tiles.append(xt)\n",
        "        return tiles\n",
        "\n",
        "    def _extract_tiles_fused(self, x_left: torch.Tensor, x_right: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"Extract tile features from BOTH streams in ONE backbone call.\"\"\"\n",
        "        B = x_left.size(0)\n",
        "        tiles_left = self._collect_tiles(x_left)\n",
        "        tiles_right = self._collect_tiles(x_right)\n",
        "        num_tiles = len(tiles_left)\n",
        "        \n",
        "        all_tiles = torch.cat(tiles_left + tiles_right, dim=0)\n",
        "        all_feats = self.backbone(all_tiles)\n",
        "        \n",
        "        total_tiles = 2 * num_tiles\n",
        "        all_feats = all_feats.view(total_tiles, B, -1).permute(1, 0, 2)\n",
        "        feats_left = all_feats[:, :num_tiles, :]\n",
        "        feats_right = all_feats[:, num_tiles:, :]\n",
        "        return feats_left, feats_right\n",
        "\n",
        "    def forward(self, x_left: torch.Tensor, x_right: torch.Tensor) -> Tuple[torch.Tensor, ...]:\n",
        "        # Extract tile features\n",
        "        tiles_left, tiles_right = self._extract_tiles_fused(x_left, x_right)\n",
        "        \n",
        "        # Get initial context\n",
        "        ctx_left = tiles_left.mean(dim=1)\n",
        "        ctx_right = tiles_right.mean(dim=1)\n",
        "        \n",
        "        # Apply FiLM cross-conditioning\n",
        "        if self.use_film:\n",
        "            gamma_l, beta_l = self.film_left(ctx_right)\n",
        "            gamma_r, beta_r = self.film_right(ctx_left)\n",
        "            tiles_left = tiles_left * (1 + gamma_l.unsqueeze(1)) + beta_l.unsqueeze(1)\n",
        "            tiles_right = tiles_right * (1 + gamma_r.unsqueeze(1)) + beta_r.unsqueeze(1)\n",
        "        \n",
        "        # Pool tiles\n",
        "        if self.use_attention_pool:\n",
        "            f_l = self.attn_pool_left(tiles_left)\n",
        "            f_r = self.attn_pool_right(tiles_right)\n",
        "        else:\n",
        "            f_l = tiles_left.mean(dim=1)\n",
        "            f_r = tiles_right.mean(dim=1)\n",
        "        \n",
        "        # Combine and project\n",
        "        f = torch.cat([f_l, f_r], dim=1)\n",
        "        f = self.shared_proj(f)\n",
        "        \n",
        "        # All 5 predictions are independent\n",
        "        green = self.softplus(self.head_green(f))\n",
        "        dead = self.softplus(self.head_dead(f))\n",
        "        clover = self.softplus(self.head_clover(f))\n",
        "        gdm = self.softplus(self.head_gdm(f))\n",
        "        total = self.softplus(self.head_total(f))\n",
        "        \n",
        "        return green, dead, clover, gdm, total\n",
        "\n",
        "def _strip_module_prefix(sd: dict) -> dict:\n",
        "    if not sd:\n",
        "        return sd\n",
        "    keys = list(sd.keys())\n",
        "    if all(k.startswith(\"module.\") for k in keys):\n",
        "        return {k[len(\"module.\"):]: v for k, v in sd.items()}\n",
        "    return sd\n",
        "\n",
        "\n",
        "def _detect_model_config(sd_keys: set) -> dict:\n",
        "    \"\"\"Detect model configuration from state dict keys.\"\"\"\n",
        "    config = {\n",
        "        \"use_film\": any(k.startswith(\"film_left.\") or k.startswith(\"film_right.\") for k in sd_keys),\n",
        "        \"use_attention_pool\": any(k.startswith(\"attn_pool_left.\") or k.startswith(\"attn_pool_right.\") for k in sd_keys),\n",
        "        \"use_aux_heads\": any(k.startswith(\"head_state.\") or k.startswith(\"head_month.\") or k.startswith(\"head_species.\") for k in sd_keys),\n",
        "        \"has_species_head\": any(k.startswith(\"head_species.\") for k in sd_keys),\n",
        "        \"is_5head\": any(k.startswith(\"head_gdm.\") for k in sd_keys) or any(k.startswith(\"shared_proj.\") for k in sd_keys),\n",
        "    }\n",
        "    return config\n",
        "\n",
        "\n",
        "def load_fold_model(\n",
        "    path: str, \n",
        "    backbone_name: str,\n",
        "    grid: Tuple[int, int] = (2, 2),\n",
        "    use_film: bool = True,\n",
        "    use_attention_pool: bool = True,\n",
        "    use_aux_heads: bool = False,\n",
        ") -> FiveHeadDINO:\n",
        "    \"\"\"\n",
        "    Load a 5-head model checkpoint.\n",
        "    \n",
        "    Args:\n",
        "        path: Path to the checkpoint file\n",
        "        backbone_name: Backbone model name\n",
        "        grid: Tile grid configuration\n",
        "        use_film: Whether to use FiLM conditioning\n",
        "        use_attention_pool: Whether to use attention pooling\n",
        "        use_aux_heads: Whether model has auxiliary heads\n",
        "    \n",
        "    Returns:\n",
        "        Loaded model in eval mode\n",
        "    \"\"\"\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"Checkpoint not found: {path}\")\n",
        "    \n",
        "    # Load state dict\n",
        "    try:\n",
        "        raw_sd = torch.load(path, map_location=CFG.DEVICE, weights_only=True)\n",
        "    except TypeError:\n",
        "        raw_sd = torch.load(path, map_location=CFG.DEVICE)\n",
        "    \n",
        "    sd = _strip_module_prefix(raw_sd)\n",
        "    \n",
        "    # Auto-detect config from state dict\n",
        "    detected = _detect_model_config(set(sd.keys()))\n",
        "    use_film = detected[\"use_film\"] if detected[\"use_film\"] else use_film\n",
        "    use_attention_pool = detected[\"use_attention_pool\"] if detected[\"use_attention_pool\"] else use_attention_pool\n",
        "    use_aux_heads = detected[\"use_aux_heads\"]\n",
        "    \n",
        "    # Build model\n",
        "    model = FiveHeadDINO(\n",
        "        backbone_name=backbone_name,\n",
        "        grid=grid,\n",
        "        pretrained=False,\n",
        "        dropout=CFG.DROPOUT,\n",
        "        hidden_ratio=CFG.HIDDEN_RATIO,\n",
        "        use_film=use_film,\n",
        "        use_attention_pool=use_attention_pool,\n",
        "        use_aux_heads=use_aux_heads,\n",
        "    )\n",
        "    \n",
        "    # Load weights\n",
        "    result = model.load_state_dict(sd, strict=False)\n",
        "    missing = getattr(result, \"missing_keys\", [])\n",
        "    unexpected = getattr(result, \"unexpected_keys\", [])\n",
        "    \n",
        "    if missing:\n",
        "        print(f\"  Warning: Missing keys: {missing[:5]}{'...' if len(missing) > 5 else ''}\")\n",
        "    if unexpected:\n",
        "        print(f\"  Warning: Unexpected keys: {unexpected[:5]}{'...' if len(unexpected) > 5 else ''}\")\n",
        "    \n",
        "    model.to(CFG.DEVICE)\n",
        "    model.eval()\n",
        "    \n",
        "    return model\n",
        "\n",
        "def get_tta_transforms(img_size: int):\n",
        "    base = [A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ToTensorV2()]\n",
        "    original = A.Compose([A.Resize(img_size, img_size, interpolation=cv2.INTER_AREA), *base])\n",
        "    hflip = A.Compose([A.HorizontalFlip(p=1.0), A.Resize(img_size, img_size, interpolation=cv2.INTER_AREA), *base])\n",
        "    vflip = A.Compose([A.VerticalFlip(p=1.0), A.Resize(img_size, img_size, interpolation=cv2.INTER_AREA), *base])\n",
        "    return [original, hflip, vflip]\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_one_view(models: List[nn.Module], loader: DataLoader) -> np.ndarray:\n",
        "    \"\"\"Run inference for a single TTA view with fold ensemble.\"\"\"\n",
        "    out_list = []\n",
        "    \n",
        "    # Set up AMP based on device\n",
        "    use_amp = CFG.DEVICE.type == \"cuda\"\n",
        "    amp_device = \"cuda\" if use_amp else \"cpu\"\n",
        "\n",
        "    for (xl, xr) in tqdm(loader, desc=\"  Predicting\", leave=False):\n",
        "        xl = xl.to(CFG.DEVICE, non_blocking=True)\n",
        "        xr = xr.to(CFG.DEVICE, non_blocking=True)\n",
        "\n",
        "        per_model_preds = []\n",
        "        with torch.amp.autocast(amp_device, enabled=use_amp):\n",
        "            for m in models:\n",
        "                green, dead, clover, gdm, total = m(xl, xr)\n",
        "                five = torch.cat([green, dead, clover, gdm, total], dim=1)\n",
        "                five = torch.clamp(five, min=0.0)\n",
        "                per_model_preds.append(five.float().cpu())\n",
        "\n",
        "        # Average across folds\n",
        "        stacked = torch.mean(torch.stack(per_model_preds, dim=0), dim=0)\n",
        "        out_list.append(stacked.numpy())\n",
        "\n",
        "    return np.concatenate(out_list, axis=0)\n",
        "\n",
        "def get_val_transform(img_size: int) -> A.Compose:\n",
        "    \"\"\"Get standard validation transform (no TTA).\"\"\"\n",
        "    return A.Compose([\n",
        "        A.Resize(img_size, img_size, interpolation=cv2.INTER_AREA),\n",
        "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "\n",
        "def run_5head_inference(model_dir: str, backbone_name: str, test_unique, image_dir):\n",
        "    \"\"\"Run inference for all folds of 5-head model with optional TTA.\"\"\"\n",
        "    ckpt_list = get_all_fold_checkpoints(model_dir)\n",
        "    print(f\"\\n================= Loading 5-head model =================\")\n",
        "    print(f\"Backbone: {backbone_name}\")\n",
        "    print(f\"Model dir: {model_dir}\")\n",
        "    print(f\"Found {len(ckpt_list)} fold checkpoints\")\n",
        "    \n",
        "    if len(ckpt_list) == 0:\n",
        "        raise RuntimeError(f\"No checkpoints found in {model_dir}\")\n",
        "    \n",
        "    # Load all fold models\n",
        "    models = []\n",
        "    for i, ckpt_path in enumerate(ckpt_list):\n",
        "        print(f\"  Loading fold {i}: {os.path.basename(ckpt_path)}\")\n",
        "        model = load_fold_model(\n",
        "            ckpt_path,\n",
        "            backbone_name=backbone_name,\n",
        "            grid=CFG.GRID,\n",
        "            use_film=CFG.USE_FILM,\n",
        "            use_attention_pool=CFG.USE_ATTENTION_POOL,\n",
        "            use_aux_heads=CFG.USE_AUX_HEADS,\n",
        "        )\n",
        "        models.append(model)\n",
        "    \n",
        "    backbone_res = int(getattr(models[0], \"input_res\", 518))\n",
        "    print(f\"Input resolution: {backbone_res}\")\n",
        "    print(f\"FiLM: {models[0].use_film}, AttnPool: {models[0].use_attention_pool}, AuxHeads: {models[0].use_aux_heads}\")\n",
        "    \n",
        "    if CFG.USE_TTA:\n",
        "        # TTA inference (3 views: original, hflip, vflip)\n",
        "        tta_trans = get_tta_transforms(backbone_res)\n",
        "        per_view_preds = []\n",
        "        \n",
        "        for i, t in enumerate(tta_trans):\n",
        "            view_name = [\"original\", \"hflip\", \"vflip\"][i]\n",
        "            print(f\"\\n--- TTA view {i+1}/{len(tta_trans)} ({view_name}, resize={backbone_res}) ---\")\n",
        "            ds = TestBiomassDataset(test_unique, t, image_dir)\n",
        "            dl = DataLoader(ds, batch_size=CFG.BATCH_SIZE, shuffle=False, num_workers=CFG.NUM_WORKERS, pin_memory=True)\n",
        "            view_5 = predict_one_view(models, dl)\n",
        "            per_view_preds.append(view_5)\n",
        "        \n",
        "        # Average TTA predictions\n",
        "        final_5 = np.mean(per_view_preds, axis=0)\n",
        "    else:\n",
        "        # Single view inference (no TTA)\n",
        "        print(f\"\\n--- Single view inference (no TTA, resize={backbone_res}) ---\")\n",
        "        transform = get_val_transform(backbone_res)\n",
        "        ds = TestBiomassDataset(test_unique, transform, image_dir)\n",
        "        dl = DataLoader(ds, batch_size=CFG.BATCH_SIZE, shuffle=False, num_workers=CFG.NUM_WORKERS, pin_memory=True)\n",
        "        final_5 = predict_one_view(models, dl)\n",
        "    \n",
        "    # Free GPU memory\n",
        "    del models\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    \n",
        "    return final_5\n",
        "\n",
        "\n",
        "def derive_dead_from_total_gdm(preds: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Derive Dead = Total - GDM.\n",
        "    \n",
        "    Since Total = Green + Dead + Clover and GDM = Green + Clover,\n",
        "    then Dead = Total - GDM.\n",
        "    \n",
        "    Args:\n",
        "        preds: (N, 5) array [Green, Dead, Clover, GDM, Total]\n",
        "    \n",
        "    Returns:\n",
        "        Modified preds with Dead replaced by max(0, Total - GDM)\n",
        "    \"\"\"\n",
        "    preds_fixed = preds.copy()\n",
        "    total = preds[:, 4]\n",
        "    gdm = preds[:, 3]\n",
        "    dead_derived = np.maximum(0, total - gdm)\n",
        "    preds_fixed[:, 1] = dead_derived\n",
        "    return preds_fixed\n",
        "\n",
        "\n",
        "def run_inference():\n",
        "    \"\"\"Run 5-head model inference with all post-processing.\"\"\"\n",
        "    print(\"\\n================= Loading test data =================\")\n",
        "    test_long = pd.read_csv(CFG.TEST_CSV)\n",
        "    test_unique = test_long.drop_duplicates(subset=[\"image_path\"]).reset_index(drop=True)\n",
        "    print(f\"Found {len(test_unique)} unique test images.\")\n",
        "    \n",
        "    print(f\"\\n================= Configuration =================\")\n",
        "    print(f\"Log target: {CFG.USE_LOG_TARGET}\")\n",
        "    print(f\"Derive Dead: {CFG.DERIVE_DEAD}\")\n",
        "    print(f\"TTA: {CFG.USE_TTA}\")\n",
        "    \n",
        "    # Run inference\n",
        "    final_5 = run_5head_inference(CFG.MODEL_DIR, CFG.BACKBONE, test_unique, CFG.TEST_IMAGE_DIR)\n",
        "    \n",
        "    # Apply inverse log transform if model was trained with log targets\n",
        "    if CFG.USE_LOG_TARGET:\n",
        "        print(\"\\n================= Applying expm1 (inverse log1p) =================\")\n",
        "        final_5 = np.expm1(final_5)\n",
        "        final_5 = np.maximum(0, final_5)  # Ensure non-negative\n",
        "    \n",
        "    # Apply Dead derivation fix\n",
        "    if CFG.DERIVE_DEAD:\n",
        "        print(\"\\n================= Applying Dead derivation fix =================\")\n",
        "        print(\"Dead = max(0, Total - GDM)\")\n",
        "        final_5 = derive_dead_from_total_gdm(final_5)\n",
        "    \n",
        "    return final_5, test_long, test_unique\n",
        "\n",
        "def create_submission(final_5, test_long, test_unique):\n",
        "    green = final_5[:, 0]\n",
        "    dead = final_5[:, 1]\n",
        "    clover = final_5[:, 2]\n",
        "    gdm = final_5[:, 3]\n",
        "    total = final_5[:, 4]\n",
        "\n",
        "    def nnz(x):\n",
        "        x = np.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    green, dead, clover, gdm, total = map(nnz, [green, dead, clover, gdm, total])\n",
        "\n",
        "    wide = pd.DataFrame(\n",
        "        {\n",
        "            \"image_path\": test_unique[\"image_path\"],\n",
        "            \"Dry_Green_g\": green,\n",
        "            \"Dry_Dead_g\": dead,\n",
        "            \"Dry_Clover_g\": clover,\n",
        "            \"GDM_g\": gdm,\n",
        "            \"Dry_Total_g\": total,\n",
        "        }\n",
        "    )\n",
        "\n",
        "    long_preds = wide.melt(\n",
        "        id_vars=[\"image_path\"],\n",
        "        value_vars=CFG.ALL_TARGET_COLS,\n",
        "        var_name=\"target_name\",\n",
        "        value_name=\"target\",\n",
        "    )\n",
        "\n",
        "    sub = pd.merge(\n",
        "        test_long[[\"sample_id\", \"image_path\", \"target_name\"]],\n",
        "        long_preds,\n",
        "        on=[\"image_path\", \"target_name\"],\n",
        "        how=\"left\",\n",
        "    )[[\"sample_id\", \"target\"]]\n",
        "\n",
        "    sub[\"target\"] = np.nan_to_num(sub[\"target\"], nan=0.0, posinf=0.0, neginf=0.0)\n",
        "    sub.to_csv(CFG.SUBMISSION_FILE, index=False)\n",
        "    print(f\"\\nðŸŽ‰ Generated submission file: {CFG.SUBMISSION_FILE}\")\n",
        "    print(sub.head())\n",
        "    return sub, wide\n",
        "\n",
        "def visualize_predictions(final_5, wide_df):\n",
        "    \"\"\"Visualize 5-head model predictions.\"\"\"\n",
        "    plt.style.use('dark_background')\n",
        "    fig = plt.figure(figsize=(16, 10))\n",
        "    gs = GridSpec(2, 3, figure=fig, hspace=0.35, wspace=0.3)\n",
        "    \n",
        "    colors = ['#00d9ff', '#ff006e', '#8338ec', '#ffbe0b', '#06ffa5']\n",
        "    target_names = ['Green', 'Dead', 'Clover', 'GDM', 'Total']\n",
        "    \n",
        "    # Model info\n",
        "    backbone_short = CFG.BACKBONE.replace(\"vit_\", \"\").replace(\"_dinov2.lvd142m\", \"\").replace(\"_dinov2\", \"\")\n",
        "    features = []\n",
        "    if CFG.USE_LOG_TARGET:\n",
        "        features.append(\"log\")\n",
        "    if CFG.DERIVE_DEAD:\n",
        "        features.append(\"dead_fix\")\n",
        "    if CFG.USE_TTA:\n",
        "        features.append(\"TTA\")\n",
        "    features_str = \", \".join(features) if features else \"none\"\n",
        "    \n",
        "    # Mean predictions per target\n",
        "    ax1 = fig.add_subplot(gs[0, 0])\n",
        "    means = [final_5[:, i].mean() for i in range(5)]\n",
        "    bars = ax1.bar(target_names, means, color=colors, alpha=0.8)\n",
        "    ax1.set_xlabel('Target', fontsize=11, fontweight='bold')\n",
        "    ax1.set_ylabel('Mean Prediction (g)', fontsize=11, fontweight='bold')\n",
        "    ax1.set_title(f'5-Head Model ({backbone_short})\\n[{features_str}]', fontsize=13, fontweight='bold')\n",
        "    ax1.tick_params(axis='x', rotation=45)\n",
        "    ax1.grid(axis='y', alpha=0.2, linestyle='--')\n",
        "    for bar, val in zip(bars, means):\n",
        "        ax1.text(bar.get_x() + bar.get_width()/2, val + max(means)*0.02, \n",
        "                f'{val:.1f}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
        "    \n",
        "    # Biomass composition pie chart\n",
        "    ax2 = fig.add_subplot(gs[0, 1])\n",
        "    biomass_totals = wide_df[['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g']].sum()\n",
        "    wedges, texts, autotexts = ax2.pie(biomass_totals, labels=['Green', 'Dead', 'Clover'],\n",
        "                                         autopct='%1.1f%%', startangle=90,\n",
        "                                         colors=['#06ffa5', '#ff006e', '#ffbe0b'],\n",
        "                                         explode=(0.05, 0.05, 0.05),\n",
        "                                         textprops={'fontsize': 11, 'fontweight': 'bold'})\n",
        "    ax2.set_title('Biomass Composition', fontsize=13, fontweight='bold')\n",
        "    \n",
        "    # Standard deviation per target\n",
        "    ax3 = fig.add_subplot(gs[0, 2])\n",
        "    stds = [final_5[:, i].std() for i in range(5)]\n",
        "    bars = ax3.bar(target_names, stds, color=colors, alpha=0.8)\n",
        "    ax3.set_xlabel('Target', fontsize=11, fontweight='bold')\n",
        "    ax3.set_ylabel('Std Dev (g)', fontsize=11, fontweight='bold')\n",
        "    ax3.set_title('Prediction Variability', fontsize=13, fontweight='bold')\n",
        "    ax3.tick_params(axis='x', rotation=45)\n",
        "    ax3.grid(axis='y', alpha=0.2, linestyle='--')\n",
        "    \n",
        "    # Distribution percentiles\n",
        "    ax4 = fig.add_subplot(gs[1, :])\n",
        "    percentiles = [10, 25, 50, 75, 90]\n",
        "    for i, name in enumerate(target_names):\n",
        "        values = final_5[:, i]\n",
        "        perc_values = np.percentile(values, percentiles)\n",
        "        ax4.plot(percentiles, perc_values, marker='o', linewidth=2.5, \n",
        "                label=name, color=colors[i], markersize=8, alpha=0.9)\n",
        "    ax4.set_xlabel('Percentile', fontsize=12, fontweight='bold')\n",
        "    ax4.set_ylabel('Biomass Prediction (g)', fontsize=12, fontweight='bold')\n",
        "    ax4.set_title('Prediction Distribution Analysis', fontsize=14, fontweight='bold')\n",
        "    ax4.legend(loc='best', framealpha=0.9, fontsize=10)\n",
        "    ax4.grid(True, alpha=0.3, linestyle='--')\n",
        "    ax4.set_xticks(percentiles)\n",
        "    \n",
        "    plt.savefig('5head_predictions.png', dpi=150, bbox_inches='tight', \n",
        "                facecolor='#1a1a1a', edgecolor='none')\n",
        "    plt.show()\n",
        "    print(\"\\nðŸ“Š Visualization saved: 5head_predictions.png\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run inference\n",
        "    final_5, df_long, df_unique = run_inference()\n",
        "    \n",
        "    # Create submission\n",
        "    sub, wide_df = create_submission(final_5, df_long, df_unique)\n",
        "    \n",
        "    # Visualize\n",
        "    print(\"\\n================= Generating Visualizations =================\")\n",
        "    visualize_predictions(final_5, wide_df)\n",
        "    \n",
        "    # Cleanup\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad5859f0",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86c08727",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "databundleVersionId": 14254895,
          "isSourceIdPinned": false,
          "sourceId": 112509,
          "sourceType": "competition"
        },
        {
          "sourceId": 272104372,
          "sourceType": "kernelVersion"
        },
        {
          "isSourceIdPinned": false,
          "modelId": 487624,
          "modelInstanceId": 471723,
          "sourceId": 630489,
          "sourceType": "modelInstanceVersion"
        },
        {
          "isSourceIdPinned": false,
          "modelId": 487624,
          "modelInstanceId": 471723,
          "sourceId": 638209,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "dockerImageVersionId": 31193,
      "isGpuEnabled": true,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 126.613443,
      "end_time": "2025-11-26T12:41:58.238412",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-11-26T12:39:51.624969",
      "version": "2.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
